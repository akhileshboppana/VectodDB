{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Install 'pymilvus', the Python SDK for Milvus, an open-source vector database.\n",
        " Milvus is used for managing, storing, and searching large-scale vector data."
      ],
      "metadata": {
        "id": "wJRLaEfyy4pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymilvus"
      ],
      "metadata": {
        "id": "jsqUF8TSzod3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install 'milvus', a high-performance vector database used for similarity search in large datasets."
      ],
      "metadata": {
        "id": "-WTZyqUszeM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install milvus"
      ],
      "metadata": {
        "id": "jswjOYoRzrH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install 'sentence-transformers', a library for computing dense vector representations of sentences.\n",
        "This library provides easy-to-use models for tasks like semantic search, clustering, and more."
      ],
      "metadata": {
        "id": "XAoewbgszXAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7McuFaOczyCw",
        "outputId": "4b24b04b-741e-41b3-8663-a2ecbfc2f74e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install 'grpcio', a package that provides support for gRPC (gRPC Remote Procedure Calls).\n",
        " gRPC is a high-performance, open-source framework for building distributed systems and APIs.\n",
        " By specifying '1.60.0', we ensure compatibility with other packages that might require this version."
      ],
      "metadata": {
        "id": "mxgRkuTv0JIp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIaPBEeB4eTo"
      },
      "outputs": [],
      "source": [
        "!pip install grpcio==1.60.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjpvu7Gs5KW_"
      },
      "outputs": [],
      "source": [
        "!pip show grpcio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx7zSqpi6wHv"
      },
      "outputs": [],
      "source": [
        "!pip install --force-reinstall grpcio==1.60.0 pymilvus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SAdms-y_3FHC"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from milvus import default_server\n",
        "from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting the default milvus server instance\n",
        "Establish a connection to the running Milvus server. The connection parameters include the host\n",
        "(localhost) and the port number on which the server is listening, provided by default_server.listen_port.\n",
        "This connection allows performing various operations on the Milvus server, such as creating collections,\n",
        "inserting data, and running queries."
      ],
      "metadata": {
        "id": "ThUgEfRt0x4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "flUtgu3T7WAA"
      },
      "outputs": [],
      "source": [
        "default_server.start()\n",
        "connections.connect(host=\"127.0.0.1\", port=default_server.listen_port)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model (\"paraphrase-multilingual-MiniLM-L12-v2\") is pre-trained to handle multiple languages\n",
        "and is commonly used for tasks like paraphrase identification and semantic search.\n",
        "\n",
        "This model (\"paraphrase-multilingual-MiniLM-L12-v2-fine-tuned-3\") is fine-tuned to improve performance\n",
        "on specific tasks or datasets, potentially enhancing the accuracy of the embeddings it generates.\n",
        "\n",
        "This model (\"psais-paraphrase-multilingual-MiniLM-L12-v2-5shot\") is fine-tuned using a few-shot learning\n",
        "approach, which means it is optimized with a small number of training examples to perform well on specific tasks."
      ],
      "metadata": {
        "id": "WJwpLkB51zmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BctiVQ_D7pCy"
      },
      "outputs": [],
      "source": [
        "v12 = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "ft3_v12 = SentenceTransformer(\"Sprylab/paraphrase-multilingual-MiniLM-L12-v2-fine-tuned-3\")\n",
        "ft5_v12 = SentenceTransformer(\"hroth/psais-paraphrase-multilingual-MiniLM-L12-v2-5shot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zcu5DH6d8e40"
      },
      "outputs": [],
      "source": [
        "# COLLECTION_V12: This collection will store the embeddings generated by the base model.\n",
        "# COLLECTION_V12_Q: This collection will store the quantized embeddings generated by the base model.\n",
        "COLLECTION_V12 = \"Multilingual_MiniLM_V12\"\n",
        "COLLECTION_V12_Q = \"Multilingual_MiniLM_V12_Quantized\"\n",
        "DIMENSION = 384\n",
        "# start with a clean slate\n",
        "if utility.has_collection(COLLECTION_V12):\n",
        "    utility.drop_collection(COLLECTION_V12)\n",
        "if utility.has_collection(COLLECTION_V12_Q):\n",
        "    utility.drop_collection(COLLECTION_V12_Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GwOlaTD1cedr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('./game-of-thrones.csv')\n",
        "\n",
        "# Assuming 'dialogue' is the column with text data\n",
        "sentences = df['Text'].dropna().tolist()[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szPq4OAlLEbr"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"I am not the kind of girl, who should be rudely barging in on a white veil occasion, but you are not the kind of boy who should be marrying the wrong girl\",\n",
        "    \"I sneak in and see your friends and her snotty little family all dressed in pastel and she is yelling at a bridesmaid somewhere back inside a room wearing a gown shaped like a pastry\",\n",
        "    \"This is surely not what you thought it would be.\",\n",
        "    \"I lose myself in a daydream where I stand and say, 'Don't say yes, run away now I'll meet you when you're out of the church at the back door.'\",\n",
        "    \"Don't wait, or say a single vow you need to hear me out and they said, 'Speak now'.\",\n",
        "    \"Fond gestures are exchanged.\",\n",
        "    \"And the organ starts to play a song that sounds like a death march.\",\n",
        "    \"And I am hiding in the curtains, it seems that I was uni`nvited by your lovely bride-to-be.\",\n",
        "    \"She floats down the aisle like a pageant queen.\",\n",
        "    \"But I know you wish it was me you wish it was me don't you?\",\n",
        "    \"I hear the preacher say, 'Speak now or forever hold your peace'\",\n",
        "    \"There's the silence, there's my last chance.\",\n",
        "    \"I stand up with shaky hands, all eyes on me\",\n",
        "    \"Horrified looks from everyone in the room but I'm only looking at you.\",\n",
        "    \"And you'll say, 'Let's run away now' I'll meet you when I'm out of my tux at the back door\",\n",
        "    \"Baby, I didn't say my vows So glad you were around When they said, 'Speak now'\",\n",
        "    \"I said, 'Oh my, what a marvelous tune'\",\n",
        "    \"It was the best night, never would forget how we moved.\",\n",
        "    \"The whole place was dressed to the nines and we were dancing, dancing like we're made of starlight\",\n",
        "    \"I met Bobby on the boardwalk summer of '45\",\n",
        "    \"Picked me up late one night out the window we were seventeen and crazy running wild, wild.\",\n",
        "    \"Can't remember what song he was playing when we walked in.\",\n",
        "    \"The night we snuck into a yacht club party pretending to be a duchess and a prince.\",\n",
        "    \"He said, 'Look at you, worrying so much about things you can't change You'll spend your whole life singing the blues If you keep thinking that way'\",\n",
        "    \"He was tryna to skip rocks on the ocean saying to me 'Don't you see the starlight, starlight don't you dream impossible things'\",\n",
        "    \"Ooh, ooh he's talking crazy Ooh, ooh dancing with me Ooh, ooh we could get married Have ten kids and teach 'em how to dream\",\n",
        "    \"The way you move is like a full on rainstorm.\",\n",
        "    \"And I'm a house of cards\",\n",
        "    \"You're the kind of reckless that should send me running but I kinda know that I won't get far\",\n",
        "    \"And you stood there in front of me just close enough to touch\",\n",
        "    \"Close enough to hope you couldn't see what I was thinking of\",\n",
        "    \"Drop everything now\",\n",
        "    \"Meet me in the pouring rain\",\n",
        "    \"Kiss me on the sidewalk\",\n",
        "    \"Take away the pain\",\n",
        "    \"'Cause I see sparks fly, whenever you smile\",\n",
        "    \"Get me with those green eyes, baby as the lights go down\",\n",
        "    \"Gimme something that'll haunt me when you're not around\",\n",
        "    \"My mind forgets to remind me you're a bad idea\",\n",
        "    \"You touch me once and it's really something you find I'm even better than you imagined I would be\",\n",
        "    \"I'm on my guard for the rest of the world but with you, I know it's no good\"\n",
        "    \"And I could wait patiently but I really wish you would\"\n",
        "    \"I run my fingers through your hair and watch the lights go wild\",\n",
        "    \"Just keep on keeping your eyes on me it's just wrong enough to make it feel right\",\n",
        "    \"And lead me up the staircase won't you whisper soft and slow, I'm captivated by you, baby like a fireworks show\",\n",
        "    \"You and I walk a fragile line I have known it all this time, But I never thought I'd live to see it break\",\n",
        "    \"It's getting dark and it's all too quiet And I can't trust anything now And it's coming over you like it's all a big mistake\",\n",
        "    \"Oh, I'm holding my breath Won't lose you again\",\n",
        "    \"Something's made your eyes go cold\",\n",
        "    \"Come on, come on, don't leave me like this I thought I had you figured out\",\n",
        "    \"Something's gone terribly wrong you're all I wanted\",\n",
        "    \"Can't breathe whenever you're gone can't turn back now, I'm haunted\",\n",
        "    \"I just know You're not gone, you can't be gone, no\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63hcoYRLKSN",
        "outputId": "64e6ec6b-9b28-409a-cb88-ac55c29e3d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ktT1VN6mLNrY"
      },
      "outputs": [],
      "source": [
        "# Define the fields for the collection schema.\n",
        "# The schema includes an 'id' field which is a primary key of type INT64 and auto-generated,\n",
        "# and an 'embedding' field which is a FLOAT_VECTOR with the specified dimensionality.\n",
        "fields = [\n",
        "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
        "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=DIMENSION),\n",
        "]\n",
        "\n",
        "# Create a CollectionSchema with the defined fields.\n",
        "# The enable_dynamic_field=True parameter allows adding new fields dynamically if needed.\n",
        "schema = CollectionSchema(fields=fields, enable_dynamic_field=True)\n",
        "\n",
        "# Create the base collection in Milvus with the specified schema.\n",
        "# This collection will store the embeddings generated by the base model.\n",
        "collection_v12 = Collection(name=COLLECTION_V12, schema=schema)\n",
        "\n",
        "# Create another collection in Milvus using the same schema.\n",
        "# This collection is intended to store the quantized embeddings or embeddings from the fine-tuned model.\n",
        "collection_v12_ft5 = Collection(name=COLLECTION_V12_Q, schema=schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "j8yWKp9CLP--"
      },
      "outputs": [],
      "source": [
        "# Initialize dictionaries to store embeddings for each sentence.\n",
        "# v12_embeds: Stores embeddings generated by the base model (v12).\n",
        "# v12_q_embeds: Stores embeddings generated by the fine-tuned model (ft5_v12).\n",
        "v12_embeds = {}\n",
        "v12_q_embeds = {}\n",
        "\n",
        "# Loop through each sentence in the 'sentences' list to generate and store embeddings.\n",
        "for sentence in sentences:\n",
        "    # Encode the sentence using the base model (v12) and store the result in v12_embeds.\n",
        "    v12_embeds[sentence] = v12.encode(sentence)\n",
        "\n",
        "    # Encode the sentence using the fine-tuned model (ft5_v12) and store the result in v12_q_embeds.\n",
        "    v12_q_embeds[sentence] = ft5_v12.encode(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "etjK9I5oLU9E"
      },
      "outputs": [],
      "source": [
        "# Define the parameters for creating the index.\n",
        "# index_type: The type of index to create. \"IVF_FLAT\" is a common index type for vector similarity search.\n",
        "# metric_type: The metric used to measure similarity. \"L2\" refers to Euclidean distance.\n",
        "# params: Additional parameters for the index. \"nlist\" specifies the number of clusters (or inverted lists) to use.\n",
        "index_params = {\n",
        "    \"index_type\": \"IVF_FLAT\",\n",
        "    \"metric_type\": \"L2\",\n",
        "    \"params\": {\"nlist\": 4},\n",
        "}\n",
        "\n",
        "# Create an index on the \"embedding\" field of the base collection (collection_v12) using the specified index parameters.\n",
        "# Indexing improves the efficiency of similarity searches by organizing the data in a way that allows for faster retrieval.\n",
        "collection_v12.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "\n",
        "# Load the base collection (collection_v12) into memory, making it ready for search operations.\n",
        "collection_v12.load()\n",
        "\n",
        "# Create an index on the \"embedding\" field of the quantized collection (collection_v12_ft5) using the same index parameters.\n",
        "# This prepares the quantized collection for efficient similarity searches as well.\n",
        "collection_v12_ft5.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "\n",
        "# Load the quantized collection (collection_v12_ft5) into memory, making it ready for search operations.\n",
        "collection_v12_ft5.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0xFhkteLLbdi"
      },
      "outputs": [],
      "source": [
        "# Loop through each sentence in the 'sentences' list to prepare and insert embeddings into the collections.\n",
        "for sentence in sentences:\n",
        "    # Prepare the data to insert into the base collection (collection_v12).\n",
        "    # Each entry includes the original sentence and its corresponding embedding generated by the base model (v12).\n",
        "    v12_insert = [\n",
        "        {\n",
        "            \"sentence\": sentence,\n",
        "            \"embedding\": v12_embeds[sentence]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Prepare the data to insert into the quantized collection (collection_v12_ft5).\n",
        "    # Each entry includes the original sentence and its corresponding embedding generated by the fine-tuned model (ft5_v12).\n",
        "    ft_insert = [\n",
        "        {\n",
        "            \"sentence\": sentence,\n",
        "            \"embedding\": v12_q_embeds[sentence]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Insert the prepared data into the base collection (collection_v12).\n",
        "    collection_v12.insert(v12_insert)\n",
        "\n",
        "    # Insert the prepared data into the quantized collection (collection_v12_ft5).\n",
        "    collection_v12_ft5.insert(ft_insert)\n",
        "\n",
        "# Flush the base collection to ensure all inserted data is persisted and made available for querying.\n",
        "collection_v12.flush()\n",
        "\n",
        "# Flush the quantized collection to ensure all inserted data is persisted and made available for querying.\n",
        "collection_v12_ft5.flush()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Y50tE6eALezB"
      },
      "outputs": [],
      "source": [
        "# Initialize dictionaries and lists to store search embeddings and data.\n",
        "# search_embeds: A dictionary to store the embeddings for the sentences to be searched.\n",
        "# search_data: A list to collect the embeddings to be used in the search query.\n",
        "search_embeds = {}\n",
        "search_data = []\n",
        "\n",
        "# Loop through a subset of sentences (from index 5 to 6) to generate and store embeddings for search.\n",
        "for sentence in sentences[5:7]:\n",
        "    # Encode the sentence using the fine-tuned model (ft3_v12) to generate its vector embedding.\n",
        "    vector_embedding = ft3_v12.encode(sentence)\n",
        "\n",
        "    # Store the generated embedding in the search_embeds dictionary with the sentence as the key.\n",
        "    search_embeds[sentence] = vector_embedding\n",
        "\n",
        "    # Append the generated embedding to the search_data list for use in the search query.\n",
        "    search_data.append(vector_embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAHEfcoYLhSK",
        "outputId": "de59dc26-38ba-44dc-a35d-c5131b2c777f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for first search: 0.012391805648803711\n",
            "Time for second search: 0.009213924407958984\n"
          ]
        }
      ],
      "source": [
        "# Measure the time taken for searching in the base collection (collection_v12).\n",
        "start1 = time()  # Start the timer\n",
        "\n",
        "# Perform a search in the base collection (collection_v12).\n",
        "# data: The embeddings to search for, stored in search_data.\n",
        "# anns_field: The field to search across, which is \"embedding\".\n",
        "# param: Search parameters including the metric type (\"L2\" for Euclidean distance) and nprobe (number of probes).\n",
        "# limit: The number of top results to return per search query.\n",
        "# output_fields: Fields to include in the search results, here we want to retrieve the original sentence.\n",
        "res_v12 = collection_v12.search(\n",
        "    data=search_data,\n",
        "    anns_field=\"embedding\",\n",
        "    param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 2}},\n",
        "    limit=3,\n",
        "    output_fields=[\"sentence\"]\n",
        ")\n",
        "\n",
        "# Calculate and print the time taken for the first search.\n",
        "time1 = time() - start1\n",
        "print(f\"Time for first search: {time1}\")\n",
        "\n",
        "# Measure the time taken for searching in the quantized collection (collection_v12_ft5).\n",
        "start2 = time()  # Start the timer\n",
        "\n",
        "# Perform a search in the quantized collection (collection_v12_ft5).\n",
        "# The parameters are the same as the previous search.\n",
        "res_v12_ft5 = collection_v12_ft5.search(\n",
        "    data=search_data,\n",
        "    anns_field=\"embedding\",\n",
        "    param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 2}},\n",
        "    limit=3,\n",
        "    output_fields=[\"sentence\"]\n",
        ")\n",
        "\n",
        "# Calculate and print the time taken for the second search.\n",
        "time2 = time() - start2\n",
        "print(f\"Time for second search: {time2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tBODxFV5Lj3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c021c901-42f6-41a5-9599-6a7b8d4a2ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query sentence: [First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]\n",
            "Nearest Neighbor Number 0:  We should head back to the wall. ---- 17.235008239746094\n",
            "\n",
            "Query sentence: [First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]\n",
            "Nearest Neighbor Number 1:  We should head back to the wall. ---- 17.235008239746094\n",
            "\n",
            "Query sentence: [First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]\n",
            "Nearest Neighbor Number 2: TITLE SEQUENCE[Riders from Winterfell come up behind a dazed WILL. The scene shifts to the castle, where BRAN is practicing archery and getting frustrated, under the eyes of JON SNOW and ROBB STARK. JON pats BRAN’S shoulder.] ---- 17.29852294921875\n",
            "\n",
            "Query sentence:  What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.\n",
            "Nearest Neighbor Number 0:  Do the dead frighten you? ---- 8.884984016418457\n",
            "\n",
            "Query sentence:  What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.\n",
            "Nearest Neighbor Number 1:  Do the dead frighten you? ---- 8.884984016418457\n",
            "\n",
            "Query sentence:  What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.\n",
            "Nearest Neighbor Number 2:  You don’t think he’ll ask us how they died? Get back on your horse. ---- 17.790613174438477\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the search results from the base collection (res_v12).\n",
        "# i: Index of the current query in the search results.\n",
        "# hits: List of search results (nearest neighbors) for the current query.\n",
        "for i, hits in enumerate(res_v12):\n",
        "    # Iterate over each hit (nearest neighbor) in the search results for the current query.\n",
        "    for j, hit in enumerate(hits):\n",
        "        # Print the original query sentence from the 'sentences' list using the index 'i'.\n",
        "        print(f\"Query sentence: {sentences[i]}\")\n",
        "\n",
        "        # Print the nearest neighbor's sentence and the distance to the query sentence.\n",
        "        # hit.entity.get('sentence') retrieves the sentence of the nearest neighbor.\n",
        "        # hit.distance provides the distance between the query sentence and the nearest neighbor.\n",
        "        print(f\"Nearest Neighbor Number {j}: {hit.entity.get('sentence')} ---- {hit.distance}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kNDyWw67Lmud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cdf02ba-4d07-4b4a-b37f-aa9112ddc65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query sentence: [First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]\n",
            "Nearest Neighbor Number 0:  Right. Give it here. ---- 17.779422760009766\n",
            "\n",
            "Query sentence: [First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]\n",
            "Nearest Neighbor Number 1:  Right. Give it here. ---- 17.779422760009766\n",
            "\n",
            "Query sentence: [First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]\n",
            "Nearest Neighbor Number 2: TITLE SEQUENCE[Riders from Winterfell come up behind a dazed WILL. The scene shifts to the castle, where BRAN is practicing archery and getting frustrated, under the eyes of JON SNOW and ROBB STARK. JON pats BRAN’S shoulder.] ---- 17.95140266418457\n",
            "\n",
            "Query sentence:  What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.\n",
            "Nearest Neighbor Number 0:  Do the dead frighten you? ---- 9.470251083374023\n",
            "\n",
            "Query sentence:  What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.\n",
            "Nearest Neighbor Number 1:  Do the dead frighten you? ---- 9.470251083374023\n",
            "\n",
            "Query sentence:  What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.\n",
            "Nearest Neighbor Number 2: GARED is also fleeing, and we hear strange growls and catch glimpses of the CREATURE. Both terrified RANGERS stop, some distance apart, to catch their breath. WILL sees a CREATURE behead GARED. WILL sinks to his knees and the CREATURE tosses GARED’S head to him.] ---- 18.266555786132812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the search results from the quantized collection (res_v12_ft5).\n",
        "# i: Index of the current query in the search results.\n",
        "# hits: List of search results (nearest neighbors) for the current query.\n",
        "for i, hits in enumerate(res_v12_ft5):\n",
        "    # Iterate over each hit (nearest neighbor) in the search results for the current query.\n",
        "    for j, hit in enumerate(hits):\n",
        "        # Print the original query sentence from the 'sentences' list using the index 'i'.\n",
        "        print(f\"Query sentence: {sentences[i]}\")\n",
        "\n",
        "        # Print the nearest neighbor's sentence and the distance to the query sentence.\n",
        "        # hit.entity.get('sentence') retrieves the sentence of the nearest neighbor.\n",
        "        # hit.distance provides the distance between the query sentence and the nearest neighbor.\n",
        "        print(f\"Nearest Neighbor Number {j}: {hit.entity.get('sentence')} ---- {hit.distance}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}